{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python_TextMining_ch5-.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNUEWDEKgxuORayo7Bc5H10",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GoldSurfer/TextMining/blob/main/Python_TextMining_ch5_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OZqGkOgIP-M",
        "outputId": "89ba4ceb-d8ab-4a82-ece4-49ec8744a3c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Train set size: 2034\n",
            "#Test set size: 1353\n",
            "#Selected categories: ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n",
            "#Train labels: {0, 1, 2, 3}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
        "\n",
        "newsgroups_train = fetch_20newsgroups(subset='train',\n",
        "                                      remove=('headers', 'footers', 'quotes'),\n",
        "                                      categories=categories)\n",
        "\n",
        "newsgroups_test = fetch_20newsgroups(subset='test',\n",
        "                                     remove=('headers', 'footers', 'quotes'),\n",
        "                                     categories=categories)\n",
        "\n",
        "print('#Train set size:', len(newsgroups_train.data))\n",
        "print('#Test set size:', len(newsgroups_test.data))\n",
        "print('#Selected categories:', newsgroups_train.target_names)\n",
        "print('#Train labels:', set(newsgroups_train.target))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('#Train set text samples:', newsgroups_train.data[0])\n",
        "print('#Train set label samples:', newsgroups_train.target[0])\n",
        "print('#Test set text samples:', newsgroups_test.data[0])\n",
        "print('#Test set label samples:', newsgroups_test.target[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pomPOaXLFvA",
        "outputId": "5a90c926-10d6-434f-c5fa-4ab6f3de8060"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Train set text samples: Hi,\n",
            "\n",
            "I've noticed that if you only save a model (with all your mapping planes\n",
            "positioned carefully) to a .3DS file that when you reload it after restarting\n",
            "3DS, they are given a default position and orientation.  But if you save\n",
            "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
            "know why this information is not stored in the .3DS file?  Nothing is\n",
            "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
            "I'd like to be able to read the texture rule information, does anyone have \n",
            "the format for the .PRJ file?\n",
            "\n",
            "Is the .CEL file format available from somewhere?\n",
            "\n",
            "Rych\n",
            "#Train set label samples: 1\n",
            "#Test set text samples: TRry the SKywatch project in  Arizona.\n",
            "#Test set label samples: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newsgroups_train.target_names"
      ],
      "metadata": {
        "id": "Sa7pfem_MBmq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6e147eb-07c9-4263-e038-28c2d677743e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = newsgroups_train.data\n",
        "y_train = newsgroups_train.target\n",
        "\n",
        "X_test = newsgroups_test.data\n",
        "y_test = newsgroups_test.target\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer(max_features=2000, min_df=5, max_df=0.5)\n",
        "\n",
        "X_train_cv = cv.fit_transform(X_train)\n",
        "print('Train set dimension:', X_train_cv.shape)\n",
        "X_test_cv = cv.transform(X_test)\n",
        "print('Test set dimension:', X_test_cv.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NC2NcVbONVuC",
        "outputId": "343805b6-7cb8-4b88-e02a-0fb436b63f3e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set dimension: (2034, 2000)\n",
            "Test set dimension: (1353, 2000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word, count in zip(\n",
        "    cv.get_feature_names_out()[:100], X_train_cv[0].toarray()[0, :100]\n",
        "):\n",
        "    print(word, ':', count, end=', ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Dm_ztxmTajm",
        "outputId": "c2ac8911-46d3-4a3d-a50b-538a2c292e84"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00 : 0, 000 : 0, 01 : 0, 04 : 0, 05 : 0, 10 : 0, 100 : 0, 1000 : 0, 11 : 0, 12 : 0, 128 : 0, 129 : 0, 13 : 0, 130 : 0, 14 : 0, 15 : 0, 16 : 0, 17 : 0, 18 : 0, 19 : 0, 1987 : 0, 1988 : 0, 1989 : 0, 1990 : 0, 1991 : 0, 1992 : 0, 1993 : 0, 20 : 0, 200 : 0, 202 : 0, 21 : 0, 22 : 0, 23 : 0, 24 : 0, 25 : 0, 256 : 0, 26 : 0, 27 : 0, 28 : 0, 2d : 0, 30 : 0, 300 : 0, 31 : 0, 32 : 0, 33 : 0, 34 : 0, 35 : 0, 39 : 0, 3d : 0, 40 : 0, 400 : 0, 42 : 0, 45 : 0, 50 : 0, 500 : 0, 60 : 0, 600 : 0, 65 : 0, 70 : 0, 75 : 0, 80 : 0, 800 : 0, 90 : 0, 900 : 0, 91 : 0, 92 : 0, 93 : 0, 95 : 0, _the : 0, ability : 0, able : 1, abortion : 0, about : 1, above : 0, absolute : 0, absolutely : 0, ac : 0, accept : 0, acceptable : 0, accepted : 0, access : 0, according : 0, account : 0, accurate : 0, across : 0, act : 0, action : 0, actions : 0, active : 0, activities : 0, activity : 0, acts : 0, actual : 0, actually : 0, ad : 0, add : 0, added : 0, addition : 0, additional : 0, address : 0, "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "NB_clf = MultinomialNB()\n",
        "NB_clf.fit(X_train_cv, y_train)\n",
        "\n",
        "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_cv, y_train)))\n",
        "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_cv, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMNKWwqin959",
        "outputId": "2f12c98c-748d-4bbc-b977-7f84562a696b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set score: 0.824\n",
            "Test set score: 0.732\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('#First document and label in test data:', X_test[0], y_test[0])\n",
        "print('#Second document and label in test data:', X_test[1], y_test[1])\n",
        "\n",
        "pred = NB_clf.predict(X_test_cv[:2])\n",
        "\n",
        "print('#Predicted labels:', pred)\n",
        "print(\n",
        "    '#Predicted categories:',\n",
        "    newsgroups_train.target_names[pred[0]],\n",
        "    newsgroups_train.target_names[pred[1]]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DS_cvLX16-YS",
        "outputId": "7f1ecece-5f7c-425c-a44a-2c8130be2ab8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#First document and label in test data: TRry the SKywatch project in  Arizona. 2\n",
            "#Second document and label in test data: The Vatican library recently made a tour of the US.\n",
            " Can anyone help me in finding a FTP site where this collection is \n",
            " available. 1\n",
            "#Predicted labels: [2 1]\n",
            "#Predicted categories: sci.space comp.graphics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6k2Lx2jp9GN_",
        "outputId": "f7bf98a5-ba1c-4cf6-f5a4-14763496d9b1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'TRry the SKywatch project in  Arizona.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tj0VO-J9h8k",
        "outputId": "99a629d8-22d2-4508-dcd7-2a14e1aa444a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=2000, min_df=5, max_df=0.5)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "NB_clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train)))\n",
        "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ui6pyksU9kp9",
        "outputId": "8b2486f3-b764-487b-f984-804c637befdd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set score: 0.862\n",
            "Test set score: 0.741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def top10_features(classifier, vectorizer, categories):\n",
        "    feature_names = np.asarray(vectorizer.get_feature_names_out())\n",
        "    for i, category in enumerate(categories):\n",
        "        top10 = np.argsort(-classifier.coef_[i])[:10]\n",
        "        print(\"%s: %s\" % (category, \", \".join(feature_names[top10])))\n",
        "\n",
        "top10_features(NB_clf, tfidf, newsgroups_train.target_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsZ86w3dBIhX",
        "outputId": "019d00c8-ef93-4caa-bca2-135e3c534226"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alt.atheism: you, not, are, be, this, have, as, what, they, if\n",
            "comp.graphics: you, on, graphics, this, have, any, can, or, with, thanks\n",
            "sci.space: space, on, you, be, was, this, as, they, have, are\n",
            "talk.religion.misc: you, not, he, are, as, this, be, god, was, they\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "LR_clf = LogisticRegression()\n",
        "\n",
        "LR_clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print('Train set score: {:.3f}'.format(LR_clf.score(X_train_tfidf, y_train)))\n",
        "print('Test set score: {:.3f}'.format(LR_clf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "id": "ESG3GvMdCgML",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56f9d7a8-756c-4ecb-aad0-0d8d9553bc7a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set score: 0.930\n",
            "Test set score: 0.734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import RidgeClassifier\n",
        "\n",
        "ridge_clf = RidgeClassifier()\n",
        "ridge_clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
        "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irH20B-86Wya",
        "outputId": "31666a9a-823e-418f-f9aa-5b446a0a5f23"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set score: 0.960\n",
            "Test set score: 0.735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_ridge, X_val_ridge, y_train_ridge, y_val_ridge = train_test_split(\n",
        "    X_train_tfidf, y_train, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "max_score = 0\n",
        "max_alpha = 0\n",
        "\n",
        "for alpha in np.arange(0.1, 10, 0.1):\n",
        "    ridge_clf = RidgeClassifier(alpha=alpha)\n",
        "    ridge_clf.fit(X_train_ridge, y_train_ridge)\n",
        "\n",
        "    score = ridge_clf.score(X_val_ridge, y_val_ridge)\n",
        "    if score > max_score:\n",
        "        max_score = score\n",
        "        max_alpha = alpha\n",
        "\n",
        "print('Max alpha {:.3f} at max validation score {:.3f}'.format(max_alpha, max_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFlQs7Hy8GLN",
        "outputId": "07078c29-6df4-44d9-c0d2-09d5e3a9e4f8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max alpha 1.600 at max validation score 0.826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ridge_clf = RidgeClassifier(alpha=1.6)\n",
        "ridge_clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
        "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F38IKqtK5bg",
        "outputId": "0d08b5d2-1c8d-4c65-f991-551d3d48f542"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set score: 0.948\n",
            "Test set score: 0.739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top10_features(ridge_clf, tfidf, newsgroups_train.target_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3USmrS8LdFh",
        "outputId": "d30e52ec-5771-47ac-a49c-6dedcb1b4619"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alt.atheism: bobby, religion, atheism, atheists, motto, punishment, islam, deletion, islamic, satan\n",
            "comp.graphics: graphics, computer, 3d, file, image, hi, 42, using, screen, looking\n",
            "sci.space: space, orbit, nasa, spacecraft, moon, sci, launch, flight, funding, idea\n",
            "talk.religion.misc: christian, christians, fbi, blood, order, jesus, objective, children, christ, hudson\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_clf = LogisticRegression(penalty='l1', solver='liblinear', C=1)\n",
        "lasso_clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print('#Train set score: {:.3f}'.format(lasso_clf.score(X_train_tfidf, y_train)))\n",
        "print('#Test set score: {:.3f}'.format(lasso_clf.score(X_test_tfidf, y_test)))\n",
        "\n",
        "print(\n",
        "    '#Used features count: {}'.format(np.sum(lasso_clf.coef_!=0)),\n",
        "    'out of',\n",
        "    X_train_tfidf.shape[1]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmMosCMxNLwN",
        "outputId": "21ab9eff-7950-4fdf-d843-c0a8232eae64"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Train set score: 0.819\n",
            "#Test set score: 0.724\n",
            "#Used features count: 437 out of 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top10_features(lasso_clf, tfidf, newsgroups_train.target_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS9DVsL1ZHeK",
        "outputId": "56027fe4-db98-455a-adf2-a5d183ac3693"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alt.atheism: bobby, atheism, atheists, islam, religion, islamic, motto, atheist, satan, vice\n",
            "comp.graphics: graphics, image, 3d, file, computer, hi, video, files, looking, sphere\n",
            "sci.space: space, orbit, launch, nasa, spacecraft, flight, moon, dc, shuttle, solar\n",
            "talk.religion.misc: fbi, christian, christians, christ, order, jesus, children, objective, context, blood\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "tree = DecisionTreeClassifier(random_state=7)\n",
        "tree.fit(X_train_tfidf, y_train)\n",
        "print(\n",
        "    \"#Decisiion Tree Train set score: {:.3f}\".format(tree.score(X_train_tfidf, y_train))\n",
        ")\n",
        "print(\"#Decisiion Tree Test set score: {:.3f}\".format(tree.score(X_test_tfidf, y_test)))\n",
        "\n",
        "forest = RandomForestClassifier(random_state=7)\n",
        "forest.fit(X_train_tfidf, y_train)\n",
        "print(\n",
        "    '#Random Forest train set score: {:.3f}'.format(forest.score(X_train_tfidf, y_train))\n",
        ")\n",
        "print('#Random Forest test set score: {:.3f}'.format(forest.score(X_test_tfidf, y_test)))\n",
        "\n",
        "gb = GradientBoostingClassifier(random_state=7)\n",
        "gb.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print(\n",
        "    '#Gradient Boosting train set score: {:.3f}'.format(gb.score(X_train_tfidf, y_train))\n",
        ")\n",
        "print('#Gradient Boosting test set score: {:.3f}'.format(gb.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFXSPLX0ZnQN",
        "outputId": "156ff640-3b86-4687-d22f-f080b0674ab2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Decisiion Tree Train set score: 0.977\n",
            "#Decisiion Tree Test set score: 0.536\n",
            "#Random Forest train set score: 0.977\n",
            "#Random Forest test set score: 0.685\n",
            "#Gradient Boosting train set score: 0.933\n",
            "#Gradient Boosting test set score: 0.696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_feature_importances = sorted(\n",
        "    zip(tfidf.get_feature_names_out(), gb.feature_importances_),\n",
        "    key=lambda x: x[1],\n",
        "    reverse=True,\n",
        ")\n",
        "for feature, value in sorted_feature_importances[:40]:\n",
        "    print('%s: %.3f' % (feature, value), end=', '\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTLfWZZL2MDl",
        "outputId": "b549b851-ca8c-41e7-c985-7516a481c0f0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "space: 0.126, graphics: 0.080, atheism: 0.024, thanks: 0.023, file: 0.021, orbit: 0.020, jesus: 0.018, god: 0.018, hi: 0.017, nasa: 0.015, image: 0.015, files: 0.014, christ: 0.010, moon: 0.010, bobby: 0.010, launch: 0.010, looking: 0.010, christian: 0.010, atheists: 0.009, christians: 0.009, fbi: 0.009, 3d: 0.008, you: 0.008, not: 0.008, islamic: 0.007, religion: 0.007, spacecraft: 0.007, flight: 0.007, computer: 0.007, islam: 0.007, ftp: 0.006, color: 0.006, software: 0.005, atheist: 0.005, card: 0.005, people: 0.005, koresh: 0.005, his: 0.005, kent: 0.004, sphere: 0.004, "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " import nltk\n",
        " nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqA3VJ5k77Ig",
        "outputId": "c361ec4b-3066-42f9-826c-1a1e20b58234"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "cachedStopWords = stopwords.words(\"english\")\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import re\n",
        "\n",
        "RegTok = RegexpTokenizer(\"[\\w']{3,}\")\n",
        "english_stops = set(stopwords.words('english'))\n",
        "\n",
        "def tokenizer(text):\n",
        "    tokens = RegTok.tokenize(text.lower())\n",
        "\n",
        "    words = [word for word in tokens if (word not in english_stops) and len(word) > 2]\n",
        "\n",
        "    features = (list(map(lambda token: PorterStemmer().stem(token),words)))\n",
        "    return features\n",
        "\n",
        "tfidf = TfidfVectorizer(tokenizer=tokenizer, max_features=2000, min_df=5, max_df=0.5)\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_train_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "LR_clf = LogisticRegression()\n",
        "LR_clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_tfidf, y_train)))\n",
        "print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_tfidf, y_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "Yzeo0_RK2tvn",
        "outputId": "8ff39045-09f5-4f26-c106-b8cd9b7c1d64"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-0102972093c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mLR_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mLR_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#Train set score: {:.3f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLR_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m             \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m             \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"liblinear\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sag\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"saga\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m         )\n\u001b[1;32m   1516\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1353, 2034]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 library들을 import\n",
        "from nltk.corpus import stopwords\n",
        "cachedStopWords = stopwords.words(\"english\")\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import re\n",
        "\n",
        "RegTok = RegexpTokenizer(\"[\\w']{3,}\") # 정규포현식으로 토크나이저를 정의\n",
        "english_stops = set(stopwords.words('english')) #영어 불용어를 가져옴\n",
        "\n",
        "def tokenizer(text):\n",
        "    tokens = RegTok.tokenize(text.lower()) #이렇게 해도 되는지 확인\n",
        "    # stopwords 제외\n",
        "    words = [word for word in tokens if (word not in english_stops) and len(word) > 2]\n",
        "    # portr stemmer 적용\n",
        "    features = (list(map(lambda token: PorterStemmer().stem(token),words)))\n",
        "    return features\n",
        "\n",
        "tfidf = TfidfVectorizer(tokenizer=tokenizer, max_features=2000, min_df=5, max_df=0.5) # 새로 정의한 토크나이저 사용\n",
        "X_train_tfidf = tfidf.fit_transform(X_train) # train set을 변환\n",
        "X_test_tfidf = tfidf.transform(X_test) # test set을 변환\n",
        "\n",
        "#tfidf vector를 이용해서 분류기 학습\n",
        "LR_clf = LogisticRegression() #분류기 선언\n",
        "LR_clf.fit(X_train_tfidf, y_train) # train data를 이용하여 분류기를 학습\n",
        "print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_tfidf, y_train))) # train data에 대한 예측정확도 \n",
        "print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_tfidf, y_test))) # test data에 대한 예측정확도"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6ET7nZVEu-d",
        "outputId": "761e9822-0501-4012-d271-4dbb86a67ff3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Train set score: 0.930\n",
            "#Test set score: 0.751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "len(LR_clf.coef_[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJpWsKJtEoaB",
        "outputId": "1b67b516-ed6a-4f12-d825-8ff36d03373b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(tokenizer=tokenizer)\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "\n",
        "print('#Train set dimension:', X_train_tfidf.shape)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "print('#Test set dimension:', X_test_tfidf.shape)\n",
        "\n",
        "ridge_clf = RidgeClassifier(alpha=2.4)\n",
        "ridge_clf.fit(X_train_tfidf, y_train)\n",
        "print('#Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
        "print('#Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n",
        "\n",
        "NB_clf = MultinomialNB(alpha=0.01)\n",
        "NB_clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print('#Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train)))\n",
        "print('#Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YFiKdlc7kXQ",
        "outputId": "5ae11a5a-f3c6-4339-848e-d08b01b5ba3c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Train set dimension: (2034, 20085)\n",
            "#Test set dimension: (1353, 20085)\n",
            "#Train set score: 0.968\n",
            "#Test set score: 0.768\n",
            "#Train set score: 0.971\n",
            "#Test set score: 0.793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "cachedStopWords = stopwords.words(\"english\")\n",
        "tfidf = TfidfVectorizer(token_pattern= \"[a-zA-Z']{3,}\",\n",
        "                        decode_error='ignore',\n",
        "                        lowercase=True,\n",
        "                        stop_words = stopwords.words('english'),\n",
        "                        max_df=0.5,\n",
        "                        min_df=2)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "print(X_train_tfidf.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U27PHabGaBUz",
        "outputId": "842ad4eb-3ca1-42d5-f0ce-669783d9da76"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2034, 11483)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tfidf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwsA4KLSbGht",
        "outputId": "8b94c58d-0cd5-40f7-dafb-35366540a823"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<2034x11483 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 125854 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import RidgeClassifier\n",
        "ridge_clf = RidgeClassifier()\n",
        "ridge_clf.fit(X_train_tfidf, y_train)\n",
        "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
        "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ryoubts7bsGz",
        "outputId": "0d4eb17d-8075-4f23-d428-7c34567b6a52"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set score: 0.976\n",
            "Test set score: 0.766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(token_pattern=\"[a-zA-Z']{3,}\",\n",
        "                        decode_error='ignore',\n",
        "                        lowercase=True,\n",
        "                        stop_words = stopwords.words('english'),\n",
        "                        ngram_range=(1, 2),\n",
        "                        max_df=0.5,\n",
        "                        min_df=2)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "print(X_train_tfidf.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3RubloBcUGN",
        "outputId": "d0ea5b19-a1ba-45b7-d305-a91c39167814"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2034, 26550)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_features = [f for f in tfidf.get_feature_names_out() if len(f.split()) > 1]\n",
        "print('bi-gram samples:', bigram_features[:10])\n",
        "\n",
        "ridge_clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
        "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rhs5AA4Nde4_",
        "outputId": "d18337db-2027-4d5b-b408-01fdfc5234b0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bi-gram samples: [\"'cause can't\", \"'em better\", \"'expected errors'\", \"'karla' next\", \"'nodis' password\", \"'official doctrine\", \"'ok see\", \"'sci astro'\", \"'what's moonbase\", 'aas american']\n",
            "Train set score: 0.976\n",
            "Test set score: 0.773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(token_pattern=\"[a-zA-Z']{3,}\",\n",
        "                        decode_error='ignore',\n",
        "                        lowercase=True,\n",
        "                        stop_words = stopwords.words('english'),\n",
        "                        ngram_range=(1, 3),\n",
        "                        max_df=0.5,\n",
        "                        min_df=2)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "print(X_train_tfidf.shape)\n",
        "\n",
        "trigram_features = [f for f in tfidf.get_feature_names_out() if len(f.split()) > 2]\n",
        "print('tri-gram samples:', trigram_features[:10])\n",
        "\n",
        "ridge_clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
        "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38rcVVyIecks",
        "outputId": "152ef9d1-30b6-4dc5-ad72-ab534678ad09"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2034, 32943)\n",
            "tri-gram samples: [\"'em better shots\", \"'expected errors' basically\", \"'karla' next one\", \"'nodis' password also\", \"'official doctrine think\", \"'ok see warning\", \"'what's moonbase good\", 'aas american astronautical', 'ability means infallible', 'able accept donations']\n",
            "Train set score: 0.976\n",
            "Test set score: 0.775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('daum_movie_review.csv')\n",
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RuRntVe0e46f",
        "outputId": "64754433-06e1-4f1f-f523-5944fb7f1668"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  rating        date  \\\n",
              "0                             돈 들인건 티가 나지만 보는 내내 하품만       1  2018.10.29   \n",
              "1       몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.      10  2018.10.26   \n",
              "2  이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...       8  2018.10.24   \n",
              "3                                이 정도면 볼만하다고 할 수 있음!       8  2018.10.22   \n",
              "4                                               재미있다      10  2018.10.20   \n",
              "\n",
              "    title  \n",
              "0  인피니티 워  \n",
              "1  인피니티 워  \n",
              "2  인피니티 워  \n",
              "3  인피니티 워  \n",
              "4  인피니티 워  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bad0a2d1-513c-4086-9a4b-4d30e3ce16fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>돈 들인건 티가 나지만 보는 내내 하품만</td>\n",
              "      <td>1</td>\n",
              "      <td>2018.10.29</td>\n",
              "      <td>인피니티 워</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.</td>\n",
              "      <td>10</td>\n",
              "      <td>2018.10.26</td>\n",
              "      <td>인피니티 워</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...</td>\n",
              "      <td>8</td>\n",
              "      <td>2018.10.24</td>\n",
              "      <td>인피니티 워</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>이 정도면 볼만하다고 할 수 있음!</td>\n",
              "      <td>8</td>\n",
              "      <td>2018.10.22</td>\n",
              "      <td>인피니티 워</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>재미있다</td>\n",
              "      <td>10</td>\n",
              "      <td>2018.10.20</td>\n",
              "      <td>인피니티 워</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bad0a2d1-513c-4086-9a4b-4d30e3ce16fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bad0a2d1-513c-4086-9a4b-4d30e3ce16fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bad0a2d1-513c-4086-9a4b-4d30e3ce16fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LyaPYx3E4a9V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}